# ğŸ›¸ **Spaceship Titanic Survival Prediction** ğŸš€

![Spaceship Titanic](https://www.kaggle.com/static/images/site-logo.png)

Este repositorio contiene mi soluciÃ³n al desafÃ­o de Kaggle [**Spaceship Titanic**](https://www.kaggle.com/competitions/spaceship-titanic), donde se predice si los pasajeros de una nave espacial serÃ¡n transportados a otra dimensiÃ³n.

## ğŸ“ **DescripciÃ³n del proyecto**

El objetivo del proyecto es predecir si un pasajero fue transportado en funciÃ³n de varios factores, como su edad, costo de servicios y otras caracterÃ­sticas. Para lograrlo, utilicÃ© tÃ©cnicas de **Machine Learning** y optimizaciÃ³n de hiperparÃ¡metros con las siguientes herramientas:

- **Random Forest** para el modelado predictivo.
- **Optuna** para la optimizaciÃ³n de hiperparÃ¡metros.
- **Pandas** para el manejo y anÃ¡lisis de datos.
- **Scikit-learn** para la implementaciÃ³n del modelo y las mÃ©tricas de evaluaciÃ³n.

## ğŸ“Š **Estructura del proyecto**

```
â”œâ”€â”€ datasets/                   # Datos utilizados (entrenamiento y prueba)
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks con el anÃ¡lisis y modelos
â”œâ”€â”€ src/                        # CÃ³digo fuente
â”‚   â”œâ”€â”€ data_preprocessing.py   # Scripts de preprocesamiento de datos
â”‚   â”œâ”€â”€ model_training.py       # Entrenamiento del modelo Random Forest
â”‚   â””â”€â”€ hyperparameter_tuning.py# OptimizaciÃ³n con Optuna
â””â”€â”€ README.md                   # DocumentaciÃ³n del proyecto
```

## ğŸ”§ **TecnologÃ­as Utilizadas**

- **Python 3.8+**
- **Pandas**: Para manipulaciÃ³n y anÃ¡lisis de datos.
- **Scikit-learn**: Para construir y evaluar el modelo de **Random Forest**.
- **Optuna**: Para la optimizaciÃ³n de los hiperparÃ¡metros del modelo.
- **Matplotlib y Seaborn**: Para la visualizaciÃ³n de datos.

## ğŸš€ **CÃ³mo ejecutar el proyecto**

1. Clona el repositorio:
   ```bash
   git clone https://github.com/AndreaMoraledaBlanco/AndreaMB_Spaceship_Titanic.git
   ```

2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

3. Descarga el conjunto de datos desde [Kaggle](https://www.kaggle.com/competitions/spaceship-titanic/data) y colÃ³calo en la carpeta `datasets/`.

4. Ejecuta el preprocesamiento de datos:
   ```bash
   python src/data_preprocessing.py
   ```

5. Entrena el modelo:
   ```bash
   python src/model_training.py
   ```

6. Ejecuta la optimizaciÃ³n de hiperparÃ¡metros (opcional):
   ```bash
   python src/hyperparameter_tuning.py
   ```

## ğŸ¯ **Resultados**

El modelo entrenado con **Random Forest** ha sido evaluado utilizando el conjunto de prueba y ha alcanzado un buen rendimiento en tÃ©rminos de precisiÃ³n y capacidad de generalizaciÃ³n. AdemÃ¡s, **Optuna** ha ayudado a ajustar los hiperparÃ¡metros, mejorando significativamente el desempeÃ±o del modelo.
Probamos otros algoritmos como XGBoost y Logistic Regression, pero los resultados obtenidos tuvieron peor rendimiento.

## ğŸ“ˆ **PrÃ³ximos pasos**

- Probar otros algoritmos de clasificaciÃ³n, como **LightGBM**.
- Implementar tÃ©cnicas mÃ¡s avanzadas de **Feature Engineering**.
- Visualizar la importancia de las caracterÃ­sticas para entender mejor el impacto de cada variable.
